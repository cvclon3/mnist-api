# Руководство по разработке API и веб-интерфейса для распознавания рукописных цифр (MNIST)

## Оглавление

1.  [Введение](#1-введение)
    *   [Цель проекта](#цель-проекта)
    *   [Основные возможности](#основные-возможности)
2.  [Технологический стек](#2-технологический-стек)
3.  [Архитектура и структура проекта](#3-архитектура-и-структура-проекта)
    *   [Компоненты системы](#компоненты-системы)
    *   [Структура файлов](#структура-файлов)
4.  [Подготовка окружения и установка](#4-подготовка-окружения-и-установка)
    *   [Требования](#требования)
    *   [Установка Python](#установка-python)
    *   [Виртуальное окружение](#виртуальное-окружение)
    *   [Установка зависимостей](#установка-зависимостей)
5.  [Серверная часть (Backend): `main.py`](#5-серверная-часть-backend-mainpy)
    *   [Инициализация FastAPI и настройка](#инициализация-fastapi-и-настройка)
    *   [Загрузка модели TensorFlow/Keras](#загрузка-модели-tensorflowkeras)
    *   [Предобработка изображений: `preprocess_image`](#предобработка-изображений-preprocess_image)
    *   [API Endpoint: Главная страница (`/`)](#api-endpoint-главная-страница-)
    *   [API Endpoint: Распознавание цифры (`/predict/`)](#api-endpoint-распознавание-цифры-predict)
    *   [API Endpoint: Получение примеров (`/examples/`)](#api-endpoint-получение-примеров-examples)
    *   [Запуск сервера](#запуск-сервера)
6.  [Клиентская часть (Frontend): `index.html`](#6-клиентская-часть-frontend-indexhtml)
    *   [Структура HTML](#структура-html)
    *   [Стилизация (CSS)](#стилизация-css)
    *   [Логика JavaScript](#логика-javascript)
        *   [Инициализация и получение элементов DOM](#инициализация-и-получение-элементов-dom)
        *   [Переключение режимов (Рисование/Загрузка)](#переключение-режимов-рисованиезагрузка)
        *   [Реализация рисования на Canvas](#реализация-рисования-на-canvas)
        *   [Обработка загрузки файлов (Выбор/Перетаскивание)](#обработка-загрузки-файлов-выборперетаскивание)
        *   [Загрузка и отображение примеров](#загрузка-и-отображение-примеров)
        *   [Отправка данных на сервер для распознавания](#отправка-данных-на-сервер-для-распознавания)
        *   [Отображение результатов](#отображение-результатов)
7.  [Модель машинного обучения (`my_mnist_model_savedmodel.keras`)](#7-модель-машинного-обучения-my_mnist_model_savedmodelkeras)
8.  [Взаимодействие клиента и сервера](#8-взаимодействие-клиента-и-сервера)
9.  [Тестирование](#9-тестирование)
    *   [Ручное тестирование интерфейса](#ручное-тестирование-интерфейса)
    *   [Тестирование API (Swagger UI/cURL)](#тестирование-api-swagger-uicurl)
10. [Возможные проблемы и их решения](#10-возможные-проблемы-и-их-решения)
11. [Развертывание (Deployment)](#11-развертывание-deployment)
    *   [Локальный запуск](#локальный-запуск)
    *   [Docker](#docker)
    *   [Продакшн сервер](#продакшн-сервер)
12. [Дальнейшее развитие](#12-дальнейшее-развитие)
13. [Заключение](#13-заключение)

## 1. Введение

Данное руководство представляет собой подробное описание процесса разработки веб-приложения для распознавания рукописных цифр. Система использует модель машинного обучения, обученную на датасете MNIST, и предоставляет интерактивный веб-интерфейс для пользователей, а также API для интеграции.

### Цель проекта

Создать простое, но функциональное веб-приложение, демонстрирующее возможности интеграции ML-модели (TensorFlow/Keras) с современным веб-фреймворком (FastAPI) и интерактивным пользовательским интерфейсом (HTML/CSS/JS).

### Основные возможности

*   Распознавание цифр, нарисованных пользователем на холсте (Canvas).
*   Распознавание цифр из загруженных пользователем изображений.
*   Возможность загрузки и распознавания предустановленных примеров цифр.
*   Отображение распознанной цифры, уверенности модели и времени обработки.
*   API endpoint для программного распознавания изображений.

## 2. Технологический стек

*   **Python 3.9+:** Основной язык программирования для серверной части.
*   **FastAPI:** Современный, быстрый (высокопроизводительный) веб-фреймворк для создания API на Python 3.7+, основанный на стандартных подсказках типов Python.
*   **TensorFlow/Keras:** Библиотека с открытым исходным кодом для машинного обучения, используемая для загрузки и выполнения предварительно обученной модели распознавания цифр.
*   **Pillow (PIL Fork):** Библиотека для открытия, манипулирования и сохранения множества различных форматов файлов изображений. Используется для предобработки изображений перед подачей в модель.
*   **NumPy:** Фундаментальная библиотека для научных вычислений в Python. Используется для работы с массивами изображений и результатами предсказаний модели.
*   **Uvicorn:** Молниеносный ASGI-сервер, используемый для запуска FastAPI-приложения.
*   **HTML5:** Стандарт разметки для создания структуры веб-страницы.
*   **CSS3:** Язык для описания внешнего вида веб-страницы. (В данном проекте стили встроены в HTML).
*   **JavaScript (Vanilla JS):** Язык программирования для добавления интерактивности на веб-страницу (рисование, обработка событий, AJAX-запросы к API).
*   **Canvas API:** Встроенный в браузер API для рендеринга 2D-графики с использованием JavaScript. Используется для создания области рисования цифр.
*   **python-multipart:** Необходим FastAPI для обработки данных форм (включая загрузку файлов).

## 3. Архитектура и структура проекта

### Компоненты системы

1.  **Серверное приложение (`main.py`):** Ядро системы. Отвечает за:
    *   Прием HTTP-запросов.
    *   Загрузку ML-модели при старте.
    *   Предобработку полученных изображений.
    *   Получение предсказаний от модели.
    *   Отправку результатов обратно клиенту.
    *   Обслуживание статических файлов (HTML, CSS, JS, изображения).
2.  **Клиентский интерфейс (`index.html`):** Веб-страница, с которой взаимодействует пользователь. Отвечает за:
    *   Отображение элементов управления (кнопки, холст, поле загрузки).
    *   Реализацию рисования на холсте.
    *   Обработку загрузки файлов.
    *   Отправку изображения на сервер через API.
    *   Отображение полученных от сервера результатов.
3.  **Модель Машинного Обучения (`my_mnist_model_savedmodel.keras`):** Предварительно обученная нейронная сеть (в формате Keras SavedModel), способная классифицировать изображения 28x28 пикселей на 10 классов (цифры от 0 до 9).
4.  **Статические файлы (`static/`):** Директория, содержащая клиентский интерфейс и другие ресурсы, доступные через веб-сервер напрямую. Включает тестовые изображения цифр (`test_digits/`).

### Структура файлов

```
mnist-recognition-api/
├── main.py                # Основной файл серверного приложения FastAPI
├── my_mnist_model_savedmodel.keras # Предварительно обученная модель Keras
├── requirements.txt       # Список зависимостей Python
├── How-to-do.md           # (Черновик методички, не используется напрямую)
└── static/
    ├── index.html         # Файл HTML с пользовательским интерфейсом
    └── test_digits/       # Директория с примерами изображений цифр
        ├── 0.jpg
        ├── 1.jpg
        # ... и т.д. до 9.jpg
```

## 4. Подготовка окружения и установка

### Требования

*   Python 3.9 или новее.
*   `pip` (менеджер пакетов Python).
*   Git (опционально, для клонирования репозитория).

### Установка Python

Загрузите и установите Python с [официального сайта](https://www.python.org/downloads/), если он еще не установлен. Убедитесь, что `python` и `pip` добавлены в `PATH` вашей системы.

### Виртуальное окружение

Крайне рекомендуется использовать виртуальное окружение для изоляции зависимостей проекта.

1.  **Создайте** виртуальное окружение в директории проекта:
    ```bash
    python -m venv venv
    ```
2.  **Активируйте** его:
    *   **Windows (cmd/powershell):**
        ```bash
        venv\Scripts\activate
        ```
    *   **Linux/macOS (bash/zsh):**
        ```bash
        source venv/bin/activate
        ```
    После активации в начале командной строки появится префикс `(venv)`.

### Установка зависимостей

1.  Убедитесь, что файл `requirements.txt` находится в корневой директории проекта и содержит:
    ```text
    fastapi==0.109.1
    uvicorn[standard]==0.27.0 # [standard] включает поддержку веб-сокетов и http-tools
    numpy==1.26.4
    Pillow==10.2.0
    tensorflow==2.15.0
    python-multipart==0.0.9
    logging # Стандартная библиотека, указывать не обязательно, но для ясности можно
    ```
    *Примечание: Версии могут быть обновлены, но указанные версии гарантированно работают вместе.*

2.  Установите зависимости, находясь в активированном виртуальном окружении:
    ```bash
    pip install -r requirements.txt
    ```

## 5. Серверная часть (Backend): `main.py`

Файл `main.py` содержит всю логику серверного приложения FastAPI.

### Инициализация FastAPI и настройка

В начале файла импортируются необходимые библиотеки и настраивается базовое логирование.

```python
# Импорт необходимых библиотек
import numpy as np  # Для работы с числовыми массивами
import logging  # Для логирования событий
from fastapi import FastAPI, UploadFile, File, HTTPException  # Основные компоненты FastAPI
from fastapi.responses import JSONResponse, FileResponse, HTMLResponse  # Типы ответов API
from fastapi.middleware.cors import CORSMiddleware  # Для обработки CORS
from fastapi.staticfiles import StaticFiles  # Для обслуживания статических файлов
from PIL import Image  # Для работы с изображениями
import io  # Для работы с потоками данных
import tensorflow as tf  # Для работы с ML моделью
from pathlib import Path  # Для работы с путями файлов
import time  # Для измерения времени выполнения
import os  # Для работы с файловой системой

# Настройка системы логирования
logging.basicConfig(level=logging.INFO)  # Устанавливаем уровень логирования INFO
logger = logging.getLogger(__name__)  # Создаем логгер для текущего модуля

# Создание экземпляра FastAPI приложения с метаданными
app = FastAPI(
    title="MNIST Digit Recognition API",  # Название API
    description="API для распознавания рукописных цифр с использованием модели Keras",  # Описание
    version="1.0.0"  # Версия API
)
```

**CORS (Cross-Origin Resource Sharing):** Настраивается для того, чтобы браузер разрешал веб-странице (загруженной, например, с `localhost:8000`) отправлять запросы к API на том же `localhost:8000`. Здесь разрешены запросы с любых источников (`allow_origins=["*"]`), что удобно для разработки, но в продакшене следует указывать конкретные домены.

```python
# Настройка CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Разрешаем запросы со всех доменов (осторожно в продакшене!)
    allow_methods=["*"],  # Разрешаем все HTTP методы (GET, POST, etc.)
    allow_headers=["*"],  # Разрешаем все заголовки
)
```

**Статические файлы:** Директория `static/` монтируется по пути `/static`. Это позволяет серверу FastAPI напрямую отдавать файлы из этой директории (например, `index.html`, изображения примеров). Также создается директория для примеров, если она отсутствует.

```python
# Создаем директорию для тестовых изображений, если её нет
os.makedirs("static/test_digits", exist_ok=True)
# Монтируем статическую директорию для обслуживания файлов
app.mount("/static", StaticFiles(directory="static"), name="static")
```

### Загрузка модели TensorFlow/Keras

Модель загружается один раз при старте приложения. Это экономит время, так как не нужно загружать её при каждом запросе. Используется формат Keras SavedModel.

```python
# Загрузка ML модели
MODEL_PATH = 'my_mnist_model_savedmodel.keras'  # Путь к файлу модели
try:
    # Загружаем модель с помощью TensorFlow/Keras
    model = tf.keras.models.load_model(MODEL_PATH)
    logger.info(f"Модель успешно загружена из {MODEL_PATH}")
except Exception as e:
    # В случае ошибки загрузки модели логируем и прекращаем работу
    logger.error(f"Ошибка загрузки модели: {str(e)}")
    raise RuntimeError(f"Не удалось загрузить модель: {str(e)}")
```

### Предобработка изображений: `preprocess_image`

Эта функция критически важна. Она принимает изображение (в формате Pillow `Image`) и преобразует его в формат, который ожидает модель MNIST:

1.  **Конвертация в grayscale (`'L'`):** Изображение преобразуется в черно-белое.
2.  **Изменение размера (`resize((28, 28))`):** Размер приводится к 28x28 пикселей, как в датасете MNIST.
3.  **Преобразование в NumPy массив:** Изображение становится массивом чисел (значения пикселей).
4.  **Инверсия цветов (`255 - image_array`):** Модель MNIST обучалась на цифрах, написанных белым цветом на черном фоне. Обычно пользователи рисуют черным на белом, поэтому цвета инвертируются.
5.  **Нормализация (`astype('float32') / 255.0`):** Значения пикселей приводятся к диапазону от 0.0 до 1.0. Это стандартная практика для нейронных сетей.
6.  **Изменение формы (`reshape(1, 28, 28, 1)`):** Модель ожидает на входе "батч" изображений. Формат `(batch_size, height, width, channels)`. Здесь:
    *   `batch_size = 1`: Мы обрабатываем одно изображение за раз.
    *   `height = 28`, `width = 28`: Размеры изображения.
    *   `channels = 1`: Изображение черно-белое (один цветовой канал).

```python
def preprocess_image(image: Image.Image) -> np.ndarray:
    """
    Предварительная обработка изображения для подачи в модель.
    """
    # Конвертируем в черно-белый формат и изменяем размер до 28x28 (как в MNIST)
    image = image.convert('L').resize((28, 28))
    # Преобразуем изображение в numpy массив
    image_array = np.array(image)
    # Инвертируем цвета (MNIST использует белые цифры на черном фоне)
    image_array = 255 - image_array
    # Нормализуем значения пикселей к диапазону [0, 1]
    image_array = image_array.astype('float32') / 255.0
    # Изменяем форму массива для соответствия ожиданиям модели:
    # (batch_size, height, width, channels) - здесь batch_size=1, channels=1
    return image_array.reshape(1, 28, 28, 1)
```

### API Endpoint: Главная страница (`/`)

Этот endpoint (`GET /`) просто возвращает содержимое файла `static/index.html` как HTML-ответ. Это точка входа для пользователя в веб-интерфейс.

```python
@app.get("/", response_class=HTMLResponse)
async def serve_interface():
    """
    Основной endpoint, возвращающий HTML интерфейс.
    """
    return FileResponse("static/index.html")
```

### API Endpoint: Распознавание цифры (`/predict/`)

Это основной рабочий endpoint (`POST /predict/`). Он принимает загружаемый файл изображения, обрабатывает его и возвращает результат распознавания.

1.  **`async def predict_digit(file: UploadFile = File(...))`**: Асинхронная функция. FastAPI ожидает получить файл в поле `file` формы (`multipart/form-data`). `UploadFile` - специальный тип FastAPI для работы с файлами.
2.  **`start_time = time.time()`**: Засекается время начала обработки для измерения производительности.
3.  **Проверка типа контента**: Убеждаемся, что загруженный файл действительно является изображением (`image/...`). Если нет, возвращается ошибка 400 (Bad Request).
4.  **Чтение и открытие файла**: `await file.read()` читает содержимое файла в память. `Image.open(io.BytesIO(contents))` создает объект изображения Pillow из байтов.
5.  **Предобработка**: Вызывается функция `preprocess_image`, описанная выше.
6.  **Предсказание**: `model.predict(image_array)` выполняет распознавание с помощью загруженной модели. Результат (`prediction`) — это массив вероятностей для каждого класса (цифры 0-9).
7.  **Извлечение результата**: `np.argmax(prediction)` находит индекс с максимальной вероятностью (это и есть распознанная цифра). `np.max(prediction)` получает саму максимальную вероятность (уверенность).
8.  **Формирование ответа**: Возвращается JSON-объект с распознанной цифрой, уверенностью и временем обработки.
9.  **Обработка ошибок**: Общий блок `try...except` ловит любые ошибки во время обработки, логирует их и возвращает клиенту ошибку 500 (Internal Server Error).

```python
@app.post("/predict/")
async def predict_digit(file: UploadFile = File(...)):
    """
    Endpoint для распознавания цифры на изображении.
    Принимает файл изображения, возвращает JSON с результатом.
    """
    start_time = time.time()  # Засекаем время начала обработки

    # Проверяем, что загруженный файл является изображением
    if not file.content_type.startswith('image/'):
        raise HTTPException(400, detail="Требуется изображение")

    try:
        # Читаем содержимое загруженного файла
        contents = await file.read()
        # Создаем объект изображения из байтов
        image = Image.open(io.BytesIO(contents))
        # Обрабатываем изображение для модели
        image_array = preprocess_image(image)

        # Получаем предсказание модели
        prediction = model.predict(image_array)
        # Определяем цифру с максимальной вероятностью
        digit = int(np.argmax(prediction))
        # Получаем значение уверенности модели
        confidence = float(np.max(prediction))

        # Возвращаем результат
        return {
            "digit": digit,
            "confidence": confidence,
            "processing_time": time.time() - start_time  # Вычисляем время выполнения
        }
    except Exception as e:
        # Логируем ошибку и возвращаем 500 статус
        logger.error(f"Ошибка при обработке запроса /predict/: {str(e)}", exc_info=True)
        raise HTTPException(500, detail="Внутренняя ошибка сервера при обработке изображения")
```

### API Endpoint: Получение примеров (`/examples/`)

Этот endpoint (`GET /examples/`) используется клиентской частью для получения списка доступных тестовых изображений. Он сканирует директорию `static/test_digits` и возвращает JSON-список имен файлов (без расширения `.jpg`).

```python
@app.get("/examples/")
async def get_examples_list():
    """
    Endpoint для получения списка доступных тестовых изображений.
    """
    # Получаем список всех .jpg файлов в директории test_digits
    examples = [f.stem for f in Path("static/test_digits").glob("*.jpg")]
    return {"examples": examples}
```

### Запуск сервера

Блок `if __name__ == "__main__":` позволяет запускать сервер напрямую из командной строки для разработки. Uvicorn запускает FastAPI приложение (`app`), делая его доступным по всем сетевым интерфейсам (`host="0.0.0.0"`) на порту `8000`.

```python
# Точка входа при запуске файла напрямую
if __name__ == "__main__":
    import uvicorn
    # Запускаем сервер Uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

## 6. Клиентская часть (Frontend): `index.html`

Файл `index.html` содержит всю разметку, стили и клиентскую логику для взаимодействия с пользователем и сервером.

### Структура HTML

*   Стандартная структура HTML5 (`<!DOCTYPE html>`, `<html>`, `<head>`, `<body>`).
*   `<head>`: Заголовок, мета-теги (кодировка, viewport), встроенные стили (`<style>`).
*   `<body>`:
    *   Заголовок (`<h1>`).
    *   Переключатель режимов (`<div class="mode-switcher">` с кнопками).
    *   Секция для рисования (`<div id="drawSection">`):
        *   Холст (`<canvas id="drawingCanvas">`).
        *   Группа кнопок (`<div class="button-group">`) для очистки, загрузки примера и распознавания нарисованного.
    *   Секция для загрузки (`<div id="uploadSection">`):
        *   Область для загрузки (`<div class="upload-section">`) с полем ввода файла (`<input type="file">`) и предпросмотром (`<img>`).
        *   Кнопка для распознавания загруженного файла.
    *   Область для вывода результата (`<div id="result">`).
    *   Скрипт (`<script>`) с JavaScript кодом.

### Стилизация (CSS)

Стили встроены в тег `<style>` внутри `<head>`. Они задают базовое оформление: центрирование контента, шрифты, размеры, цвета кнопок, внешний вид холста, области загрузки и блока результатов (включая стили для успеха и ошибки). Используются классы для стилизации и идентификаторы для доступа из JavaScript.

### Логика JavaScript

Весь JavaScript код находится внутри тега `<script>` в конце `<body>`.

#### Инициализация и получение элементов DOM

В начале скрипта получаются ссылки на все необходимые HTML-элементы с помощью `document.getElementById` для дальнейшего манипулирования. Настраивается контекст рисования (`ctx`) для Canvas.

```javascript
// Элементы интерфейса
const drawSection = document.getElementById('drawSection');
// ... (остальные элементы)
const resultDiv = document.getElementById('result');

// Настройки рисования
let isDrawing = false;
const canvas = document.getElementById('drawingCanvas');
const ctx = canvas.getContext('2d');
ctx.strokeStyle = 'white';
ctx.lineWidth = 15; // Толстая линия для лучшего распознавания MNIST-подобных цифр
ctx.lineCap = 'round'; // Скругленные концы линий

// Инициализация - заливаем холст черным цветом
clearCanvas();
```

#### Переключение режимов (Рисование/Загрузка)

Добавляются обработчики кликов на кнопки `drawModeBtn` и `uploadModeBtn`. Они показывают/скрывают соответствующие секции (`drawSection`, `uploadSection`) и меняют активный класс у кнопок для визуального выделения.

```javascript
drawModeBtn.addEventListener('click', () => {
    drawSection.style.display = 'block';
    uploadSection.style.display = 'none';
    drawModeBtn.classList.add('active');
    uploadModeBtn.classList.remove('active');
});
// Аналогично для uploadModeBtn
```

#### Реализация рисования на Canvas

*   Используются события мыши (`mousedown`, `mousemove`, `mouseup`, `mouseout`) и касаний (`touchstart`, `touchmove`, `touchend`) для поддержки как десктопных, так и мобильных устройств.
*   `startDrawing`: Устанавливает флаг `isDrawing = true` и начинает рисование с текущей точки.
*   `draw`: Если `isDrawing` равно `true`, получает координаты курсора/пальца относительно Canvas, рисует линию (`lineTo`, `stroke`) и начинает новый путь (`beginPath`, `moveTo`) для следующего сегмента.
*   `stopDrawing`: Сбрасывает флаг `isDrawing = false`.
*   `clearCanvas`: Заливает холст черным цветом, очищая предыдущий рисунок. Вызывается при инициализации и по клику на кнопку "Очистить".

```javascript
function startDrawing(e) { /* ... */ }
function draw(e) { /* ... */ }
function stopDrawing() { /* ... */ }
function clearCanvas() { /* ... */ }

// Привязка обработчиков
canvas.addEventListener('mousedown', startDrawing);
// ... (остальные события)
clearBtn.addEventListener('click', clearCanvas);
```

#### Обработка загрузки файлов (Выбор/Перетаскивание)

*   **Выбор файла:** Обработчик `change` на `fileInput` (`handleFileUpload`) срабатывает при выборе файла. Он проверяет, что файл - изображение, и использует `FileReader` для чтения файла и отображения его превью в элементе `<img>`.
*   **Перетаскивание (Drag & Drop):** Обработчики `dragover` (предотвращает стандартное поведение браузера) и `drop` на `uploadSection` позволяют пользователю перетащить файл прямо в область загрузки. При событии `drop` файл из `e.dataTransfer.files` передается в `fileInput`, и инициируется событие `change`, чтобы сработал тот же код `handleFileUpload`.

```javascript
fileInput.addEventListener('change', handleFileUpload);
uploadSection.addEventListener('dragover', (e) => e.preventDefault());
uploadSection.addEventListener('drop', (e) => { /* ... */ });

function handleFileUpload(e) { /* ... */ }
```

#### Загрузка и отображение примеров

Функция `loadExample` вызывается по клику на кнопку "Пример".

1.  Отправляет `fetch`-запрос к API endpoint `/examples/` для получения списка имен файлов примеров.
2.  Выбирает случайное имя из списка.
3.  Формирует URL к файлу примера (например, `/static/test_digits/5.jpg`).
4.  Загружает сам файл изображения с помощью `fetch` и получает его как `Blob`.
5.  Создает объект `File` из `Blob` (это нужно для единообразия с загрузкой).
6.  **В зависимости от активного режима:**
    *   **Рисование:** Использует `createImageBitmap` и `ctx.drawImage` для отрисовки примера прямо на Canvas.
    *   **Загрузка:** Устанавливает `src` элемента `preview` через `URL.createObjectURL` и программно помещает созданный `File` в `fileInput`, как будто пользователь его выбрал.
7.  Обрабатывает возможные ошибки при загрузке.

```javascript
exampleBtn.addEventListener('click', loadExample);

async function loadExample() {
    try {
        // Запрос списка примеров
        const response = await fetch('/examples/');
        const data = await response.json();
        // ... (выбор случайного, формирование URL)

        // Загрузка изображения
        const imgResponse = await fetch(exampleUrl);
        const blob = await imgResponse.blob();
        const file = new File([blob], /* ... */);

        // Отображение в зависимости от режима
        if (drawSection.style.display !== 'none') {
            const img = await createImageBitmap(blob);
            clearCanvas();
            ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
        } else {
            preview.src = URL.createObjectURL(blob);
            preview.style.display = 'block';
            fileInput.files = [file]; // Помещаем файл в input
        }
    } catch (error) {
        showResult(`Ошибка загрузки примера: ${error.message}`, false);
    }
}
```

#### Отправка данных на сервер для распознавания

Есть две функции для отправки: `sendCanvasImage` (для нарисованного) и `sendUploadedImage` (для загруженного). Обе они вызывают общую функцию `sendToServer`.

*   **`sendCanvasImage`**:
    1.  Создает временный невидимый Canvas размером 28x28.
    2.  Копирует (с масштабированием) содержимое основного Canvas на временный. *Примечание: В текущей реализации `index.html` есть дополнительный шаг инверсии и преобразования в ч/б на клиенте, который дублирует часть логики `preprocess_image` на сервере. Это можно упростить, отправляя "сырое" изображение 280x280 и полагаясь только на серверную предобработку, но текущий подход тоже рабочий, хотя и менее оптимальный.*
    3.  Использует `tempCanvas.toBlob(...)` для получения содержимого временного Canvas в формате PNG (`Blob`).
    4.  Вызывает `sendToServer` с этим `Blob`.
*   **`sendUploadedImage`**:
    1.  Проверяет, выбран ли файл в `fileInput`.
    2.  Вызывает `sendToServer` с объектом `File` из `fileInput.files[0]`.
*   **`sendToServer(imageBlob)`**:
    1.  Скрывает предыдущий результат.
    2.  Создает объект `FormData`. `FormData` необходим для отправки файлов через `fetch` (имитирует отправку HTML-формы с `enctype="multipart/form-data"`).
    3.  Добавляет `Blob` или `File` в `FormData` под ключом `file`. **Важно:** имя ключа (`'file'`) должно совпадать с именем параметра в `predict_digit(file: UploadFile = File(...))` на сервере FastAPI. Третий аргумент `formData.append('file', imageBlob, 'digit.png')` задает имя файла, которое увидит сервер.
    4.  Отправляет `POST`-запрос на `/predict/` с помощью `fetch`. В `body` передается `formData`. Заголовки `Content-Type` для `multipart/form-data` `fetch` установит автоматически при передаче `FormData`.
    5.  Обрабатывает ответ:
        *   Если `response.ok` (статус 2xx), читает JSON-ответ (`response.json()`) и вызывает `showResult` для отображения успеха.
        *   Если `response.ok` равно `false`, выбрасывает ошибку с текстом ответа сервера (который может содержать `detail` из `HTTPException`).
    6.  Обрабатывает ошибки сети или ошибки, выброшенные при не-ok ответе, и вызывает `showResult` для отображения ошибки.

```javascript
recognizeBtn.addEventListener('click', () => sendCanvasImage());
uploadRecognizeBtn.addEventListener('click', () => sendUploadedImage());

async function sendCanvasImage() {
    // ... (создание временного canvas, рисование, инверсия - как в index.html)
    tempCanvas.toBlob(async (blob) => {
        await sendToServer(blob);
    }, 'image/png');
}

async function sendUploadedImage() {
    if (!fileInput.files.length) { /* ... */ return; }
    await sendToServer(fileInput.files[0]);
}

async function sendToServer(imageBlob) {
    resultDiv.style.display = 'none';
    const formData = new FormData();
    formData.append('file', imageBlob, 'digit.png'); // Ключ 'file' важен!

    try {
        const response = await fetch('/predict/', {
            method: 'POST',
            body: formData // fetch сам установит Content-Type: multipart/form-data
        });
        if (!response.ok) { // Проверка статуса HTTP (200-299)
            throw new Error(await response.text()); // Прочитать тело ошибки
        }
        const data = await response.json(); // Парсинг JSON ответа
        showResult(/* ... форматирование успеха ... */, true);
    } catch (error) {
        console.error('Ошибка:', error);
        let message = 'Произошла ошибка при распознавании';
        try { // Попытка извлечь 'detail' из JSON-ошибки FastAPI
            const errData = JSON.parse(error.message);
            message = errData.detail || message;
        } catch (e) {}
        showResult(message, false);
    }
}
```

#### Отображение результатов

Функция `showResult(message, isSuccess)` обновляет содержимое `resultDiv`, устанавливает ему класс `success` или `error` (для соответствующего фона/цвета текста) и делает его видимым.

```javascript
function showResult(message, isSuccess) {
    resultDiv.innerHTML = message;
    resultDiv.className = isSuccess ? 'success' : 'error';
    resultDiv.style.display = 'block';
}
```

## 7. Модель машинного обучения (`my_mnist_model_savedmodel.keras`)

Это файл, содержащий архитектуру и веса обученной нейронной сети.

*   **Формат:** Keras SavedModel. Это стандартный формат TensorFlow 2.x для сохранения моделей, включающий как структуру графа вычислений, так и обученные параметры (веса). Он удобен тем, что содержит всё необходимое для загрузки и использования модели без доступа к исходному коду, который её определял.
*   **Назначение:** Модель принимает на вход тензор формы `(batch_size, 28, 28, 1)` со значениями от 0 до 1 (изображение цифры) и возвращает тензор формы `(batch_size, 10)`, где каждый элемент соответствует вероятности принадлежности к классу (цифре) от 0 до 9.
*   **Происхождение:** Предполагается, что эта модель была предварительно обучена на датасете MNIST (например, с использованием Keras API) и сохранена с помощью `model.save('my_mnist_model_savedmodel.keras')`. Процесс обучения модели выходит за рамки данного руководства, но он является необходимым предварительным шагом.

## 8. Взаимодействие клиента и сервера

1.  **Начальная загрузка:** Пользователь открывает в браузере URL, соответствующий корневому пути (`/`). Сервер (`main.py`) через endpoint `@app.get("/")` отдает файл `index.html`. Браузер загружает HTML, CSS (встроенный) и JS (встроенный).
2.  **Загрузка примеров (опционально):** Пользователь нажимает "Пример". JavaScript отправляет `GET`-запрос на `/examples/`. Сервер отвечает JSON-списком имен файлов. JavaScript выбирает случайное имя, отправляет `GET`-запрос на `/static/test_digits/{имя_файла}.jpg`. Сервер отдает статический файл изображения. JavaScript отображает его на Canvas или в `preview`.
3.  **Распознавание:**
    *   Пользователь рисует цифру или загружает файл.
    *   Пользователь нажимает "Распознать".
    *   JavaScript подготавливает изображение (из Canvas или из `fileInput`) в виде `Blob` или `File`.
    *   JavaScript создает `FormData`, добавляет туда изображение под ключом `file`.
    *   JavaScript отправляет `POST`-запрос с `FormData` на `/predict/`.
    *   Сервер (`main.py`) получает запрос в endpoint `@app.post("/predict/")`.
    *   FastAPI разбирает `multipart/form-data`, извлекает файл (`UploadFile`).
    *   Сервер читает файл, передает его в `preprocess_image`.
    *   Предобработанный `numpy.ndarray` передается в `model.predict()`.
    *   Сервер получает массив вероятностей, находит максимальную (`digit`, `confidence`).
    *   Сервер формирует JSON-ответ: `{"digit": ..., "confidence": ..., "processing_time": ...}`.
    *   Сервер отправляет JSON-ответ клиенту со статусом 200 OK (или ошибку 400/500).
    *   JavaScript получает ответ. Если ответ успешный (200 OK), он парсит JSON и вызывает `showResult` для отображения информации. Если произошла ошибка, также вызывается `showResult` с сообщением об ошибке.

## 9. Тестирование

### Ручное тестирование интерфейса

1.  Запустите сервер (`uvicorn main:app --reload`).
2.  Откройте `http://localhost:8000` в браузере.
3.  **Режим рисования:**
    *   Нарисуйте разные цифры (0-9). Убедитесь, что рисование работает плавно.
    *   Нажмите "Очистить". Холст должен очиститься.
    *   Нарисуйте цифру, нажмите "Распознать". Проверьте адекватность результата (цифра, уверенность).
    *   Нажмите "Пример". Убедитесь, что на холсте появился пример цифры. Нажмите "Распознать".
4.  **Режим загрузки:**
    *   Переключитесь в режим загрузки.
    *   Нажмите "Выбрать файл" и выберите изображение цифры с компьютера. Убедитесь, что превью отображается. Нажмите "Распознать".
    *   Перетащите файл изображения в область загрузки. Убедитесь, что превью отображается. Нажмите "Распознать".
    *   Нажмите "Пример". Убедитесь, что превью обновилось. Нажмите "Распознать".
5.  **Обработка ошибок:** Попробуйте загрузить не изображение, а другой файл (например, `.txt`). Сервер должен вернуть ошибку 400, а интерфейс - отобразить сообщение об ошибке.

### Тестирование API (Swagger UI/cURL)

*   **Swagger UI:** FastAPI автоматически генерирует интерактивную документацию API. Перейдите по адресу `http://localhost:8000/docs`. Там вы найдете endpoint `/predict/`, сможете загрузить тестовый файл изображения и отправить запрос, увидев реальный ответ сервера.
*   **cURL:** Можно использовать утилиту командной строки `curl` для отправки запросов. Создайте тестовый файл изображения (например, `test_digit.png`).
    ```bash
    curl -X POST -F "file=@test_digit.png" http://localhost:8000/predict/
    ```
    Ожидаемый ответ: JSON вида `{"digit":5,"confidence":0.998,"processing_time":0.05}` (значения будут другими).

## 10. Возможные проблемы и их решения

1.  **Ошибка загрузки модели при старте сервера:**
    *   **Причина:** Файл `my_mnist_model_savedmodel.keras` не найден или поврежден; несовместимость версий TensorFlow/Keras, с которыми модель была сохранена и с которыми она загружается.
    *   **Решение:** Проверьте путь `MODEL_PATH` в `main.py`. Убедитесь, что файл модели существует и не пустой. Попробуйте использовать ту же версию TensorFlow/Python, с которой модель сохранялась. Если модель повреждена, пересохраните её из исходного кода обучения.
2.  **Ошибка CORS:**
    *   **Причина:** Запрос к API блокируется браузером из-за политики безопасности (например, если интерфейс открыт с `file://` или другого домена/порта, а `allow_origins` настроен слишком строго).
    *   **Решение:** Убедитесь, что `CORSMiddleware` настроен правильно в `main.py`. Для разработки `allow_origins=["*"]` обычно достаточно. Проверьте консоль разработчика в браузере на наличие ошибок CORS.
3.  **Неправильное распознавание цифр:**
    *   **Причина:** Ошибки в функции `preprocess_image` (неправильный размер, инверсия, нормализация); цифра нарисована/загружена в сильно отличающемся от MNIST стиле (например, очень тонкие линии, несколько цифр на изображении). Клиентская предобработка (в `sendCanvasImage`) может конфликтовать с серверной.
    *   **Решение:** Тщательно проверьте каждый шаг в `preprocess_image` и `sendCanvasImage`. Убедитесь, что на вход модели подается массив правильной формы `(1, 28, 28, 1)` и с корректными значениями. Логируйте промежуточные изображения/массивы для отладки. Попробуйте рисовать цифры более жирно и по центру холста. Рассмотрите возможность удаления клиентской предобработки в `sendCanvasImage`, полагаясь только на серверную.
4.  **Медленное распознавание:**
    *   **Причина:** Модель выполняется на CPU, а не на GPU (если GPU доступен); загрузка модели происходит при каждом запросе (если код загрузки модели ошибочно помещен внутрь endpoint); очень большие исходные изображения требуют много времени на чтение/предобработку.
    *   **Решение:** Убедитесь, что установлена версия TensorFlow с поддержкой GPU (`tensorflow-gpu`, хотя в последних версиях это часто объединено) и драйверы настроены корректно. Проверьте, что модель загружается один раз при старте приложения. Оптимизируйте предобработку, если возможно.
5.  **Ошибки JavaScript в браузере:**
    *   **Причина:** Опечатки в коде, неправильное обращение к элементам DOM, ошибки в логике обработки событий или `fetch`-запросов.
    *   **Решение:** Используйте консоль разработчика браузера (F12) для отслеживания ошибок JavaScript и сетевых запросов. Используйте `console.log` для отладки значений переменных и потока выполнения.

## 11. Развертывание (Deployment)

### Локальный запуск

Для разработки и тестирования:

```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

*   `--reload`: Uvicorn будет автоматически перезапускаться при изменении кода.
*   `--host 0.0.0.0`: Делает сервер доступным по сети (не только с `localhost`).
*   `--port 8000`: Указывает порт.

### Docker

Контейнеризация упрощает развертывание и обеспечивает согласованность окружения.

1.  **Создайте `Dockerfile`:**
    ```dockerfile
    # Используем официальный образ Python
    FROM python:3.9-slim

    # Устанавливаем рабочую директорию
    WORKDIR /app

    # Копируем файлы зависимостей
    COPY requirements.txt .

    # Устанавливаем зависимости
    # --no-cache-dir уменьшает размер образа
    RUN pip install --no-cache-dir -r requirements.txt

    # Копируем остальной код приложения
    COPY . .

    # Указываем команду для запуска приложения при старте контейнера
    # Используем Uvicorn для запуска FastAPI приложения
    CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    ```
2.  **Соберите Docker образ:**
    ```bash
    docker build -t mnist-recognition-api .
    ```
3.  **Запустите контейнер:**
    ```bash
    docker run -d -p 8000:8000 --name mnist-app mnist-recognition-api
    ```
    *   `-d`: Запуск в фоновом режиме.
    *   `-p 8000:8000`: Проброс порта 8000 хоста на порт 8000 контейнера.
    *   `--name mnist-app`: Имя контейнера для удобства управления.

### Продакшн сервер

Для реального использования рекомендуется более надежная настройка:

1.  **ASGI-сервер:** Используйте `Uvicorn` (или `Hypercorn`) с несколькими рабочими процессами (`workers`) для лучшей производительности под нагрузкой. Запускать его лучше через менеджер процессов типа `systemd` или `supervisor` для автоматического перезапуска.
    ```bash
    # Пример команды запуска с 4 воркерами
    uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
    ```
2.  **Обратный прокси (Reverse Proxy):** Используйте веб-сервер, такой как `Nginx` или `Traefik`, перед Uvicorn. Задачи прокси:
    *   Обработка и терминирование HTTPS (SSL/TLS).
    *   Обслуживание статических файлов (эффективнее, чем через FastAPI/Uvicorn).
    *   Балансировка нагрузки (если несколько экземпляров приложения).
    *   Сжатие ответов (gzip).
    *   Установка заголовков безопасности.

    **Пример конфигурации Nginx (упрощенный):**
    ```nginx
    server {
        listen 80;
        server_name yourdomain.com; # Замените на ваш домен

        # Перенаправление HTTP на HTTPS (если настроен SSL)
        # listen 443 ssl;
        # ssl_certificate /path/to/your/fullchain.pem;
        # ssl_certificate_key /path/to/your/privkey.pem;
        # if ($scheme != "https") {
        #     return 301 https://$host$request_uri;
        # }

        location /static {
            alias /path/to/your/project/static; # Путь к статике на сервере
        }

        location / {
            proxy_pass http://127.0.0.1:8000; # Адрес запущенного Uvicorn
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
    ```

## 12. Дальнейшее развитие

*   **Улучшение модели:** Использовать более сложную архитектуру CNN, аугментацию данных при обучении, попробовать другие фреймворки (PyTorch).
*   **Улучшение интерфейса:** Сделать дизайн адаптивным, добавить визуализацию процесса обработки, историю распознаваний.
*   **Расширение API:** Добавить аутентификацию/авторизацию, лимиты запросов (rate limiting), возможность batch-обработки нескольких изображений за раз.
*   **Обработка ошибок:** Более детальная обработка ошибок на клиенте и сервере, предоставление более информативных сообщений пользователю.
*   **Оптимизация:** Оптимизировать предобработку изображений, исследовать квантизацию модели для ускорения и уменьшения размера.
*   **Мониторинг и логирование:** Интегрировать более продвинутые системы логирования (ELK stack, Graylog) и мониторинга (Prometheus, Grafana) для отслеживания производительности и ошибок в продакшене.

## 13. Заключение

Этот проект демонстрирует полный цикл создания веб-приложения с интеграцией машинного обучения. FastAPI предоставляет удобный и быстрый способ создания API, TensorFlow/Keras позволяет легко загружать и использовать ML-модели, а стандартные веб-технологии (HTML, CSS, JS, Canvas) позволяют создать интерактивный пользовательский интерфейс. Данное руководство охватывает основные шаги от настройки окружения до развертывания, объясняя ключевые моменты кода и взаимодействия компонентов системы.